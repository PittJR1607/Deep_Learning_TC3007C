{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10004339,"sourceType":"datasetVersion","datasetId":6158170},{"sourceId":10004460,"sourceType":"datasetVersion","datasetId":6158257}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"41b7905f-a070-4ffe-abfc-67fbcd2adaa9","cell_type":"markdown","source":"## TC 5033 - Deep Learning - Transformers\n\n#### Activity 3: Implementing a Translator\n\n- Objective\n\nTo understand the Transformer Architecture by Implementing a translator.\n\n- Instructions\n\n    This activity requires submission in teams. While teamwork is encouraged, each member is expected to contribute individually to the assignment. The final submission should feature the best arguments and solutions from each team member. Only one person per team needs to submit the completed work, but it is imperative that the names of all team members are listed in a Markdown cell at the very beginning of the notebook (either the first or second cell). Failure to include all team member names will result in the grade being awarded solely to the individual who submitted the assignment, with zero points given to other team members (no exceptions will be made to this rule).\n\n    Follow the provided code. The code already implements a transformer from scratch as explained in [this video](https://youtu.be/XefFj4rLHgU)\n\n    Since the provided code already implements a simple translator, your job for this assignment is to understand it fully, and document it using pictures, figures, and markdown cells.  You should test your translator with at least 10 sentences. The dataset used for this task was obtained from [Tatoeba, a large dataset of sentences and translations](https://tatoeba.org/en/downloads).\n  \n- Evaluation Criteria\n\n    - Code Readability and Comments\n    - Traning a translator\n    - Translating at least 10 sentences.\n\n- Submission\n\nSubmit this Jupyter Notebook in canvas with your complete solution, ensuring your code is well-commented and includes Markdown cells that explain your design choices, results, and any challenges you encountered.\n\n## Translation Using Transformers\n\n### Team : NoName\n#### Team Members:\n* A01661090 Juan Pablo Cabrera Quiroga\n* A01709522 Arturo Cristián Díaz López\n* A01704076 Adrián Galván Díaz\n* A01368818 Joel Sánchez Olvera\n* A01708634 Carlos Eduardo Velasco \n\n### Abstract\nThis project focuses on implementing a machine translation system using the Transformer architecture, a state-of-the-art model in natural language processing. The model is trained to translate English sentences into Spanish using a dataset derived from Tatoeba. By leveraging the core components of the Transformer, including multi-head attention and positional embeddings, this implementation aims to explore the inner workings of the architecture. The project also emphasizes code readability, documentation, and practical evaluation by testing translations on sample sentences. \n\n### Dataset\nThe dataset for this project was sourced from [Tatoeba](https://tatoeba.org/en/downloads), focusing on English and Spanish sentence pairs. The data was originally in TSV format, which we converted to a more convenient TXT format using a custom converter, allowing for seamless integration with our model. This conversion step ensures compatibility and ease of use, but it is optional and only required if working with the original TSV files.\n  \n\n### Objectives \n* Analyzing and understanding the inner workings of the Transformer model\n* Building a translator capable of converting English sentences into Spanish.\n* Creating detailed documentation using markdown cells, comments and visualizations.\n* Evaluating translation quality by using the necessary metrics.","metadata":{"id":"41b7905f-a070-4ffe-abfc-67fbcd2adaa9"}},{"id":"f140e070-7c1e-49ab-a19c-23900076765e","cell_type":"markdown","source":"## Data Preparation\nWe explore the dataset directory to verify the presence of necessary files, such as eng-spa4.txt, which contains the English-Spanish sentence pairs needed for translation.","metadata":{}},{"id":"f240f0d8-d9e0-4632-962f-1a5a7881cb5f","cell_type":"code","source":"import os\n\n# Route to the dataset run on Kaggle\ndataset_path= \"/kaggle/input/eng-spa4\"\n\nos.listdir(dataset_path)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f240f0d8-d9e0-4632-962f-1a5a7881cb5f","outputId":"4ead76e6-96b2-4e77-fc80-2fef2d3f4c38","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:25:55.560369Z","iopub.execute_input":"2024-11-25T04:25:55.560774Z","iopub.status.idle":"2024-11-25T04:25:55.572127Z","shell.execute_reply.started":"2024-11-25T04:25:55.560730Z","shell.execute_reply":"2024-11-25T04:25:55.571461Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"['eng-spa4.txt']"},"metadata":{}}],"execution_count":1},{"id":"2a88f48d-d7a7-4728-b213-e304958c08f7","cell_type":"markdown","source":"## Data Conversion -- Converting TSV to TXT\n**ONLY RUN IF NEEDED**\n\n\nThis code block reads a TSV (tab-separated values) file containing English-Spanish sentence pairs, selects the relevant columns, and saves the data as a tab-separated TXT file.","metadata":{}},{"id":"ISBDdOFprjTb","cell_type":"code","source":"#SCRIPT USADO POR EL EQUIPO\n\nimport pandas as pd\n\ninput_file = dataset_path + '/eng-spa.tsv'  # Archivo de Entrada (.tsv)\noutput_file = dataset_path + '/eng-spa4.txt'  # Archivo de Salida (.txt)\n\n# Lee el TSV con las columnas necesarias\ndata = pd.read_csv(input_file, sep='\\t', usecols=[1, 3], header=None, names=[\"English\", \"Spanish\"])\n\n# Guarda el TXT\ndata.to_csv(output_file, sep='\\t', index=False, header=False, encoding='utf-8')\n\nprint(f\"Archivo procesado como {output_file}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ISBDdOFprjTb","outputId":"c3e1c738-1a1f-4131-b16f-4e53cdc7cfe4","trusted":true},"outputs":[],"execution_count":null},{"id":"7d468e9a","cell_type":"markdown","source":"## Transformer - Attention is all you need\nThis block sets up the Transformer architecture, inspired by the \"Attention Is All You Need\" paper. It includes essential components like multi-head attention, positional encoding, and encoder-decoder blocks to enable sequence-to-sequence tasks such as language translation.\n\nFirst, we import the neccesary libraries for the project:","metadata":{"id":"7d468e9a"}},{"id":"d5dcf681","cell_type":"code","source":"# Import required libraries for the Transformer model\nimport torch  \nimport torch.nn as nn  \nimport torch.nn.functional as F  \nimport torch.optim as optim  \nfrom torch.utils.data import Dataset, DataLoader  \nfrom collections import Counter  # For vocabulary building\nimport math  \nimport numpy as np  \nimport re  # Regular expressions for text preprocessing\nfrom tqdm import tqdm  # Progress bar for loops\n\n# Set the random seed for reproducibility\ntorch.manual_seed(23)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d5dcf681","outputId":"423b5d10-8002-4710-ca45-e33532f57dda","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:25:56.957856Z","iopub.execute_input":"2024-11-25T04:25:56.958189Z","iopub.status.idle":"2024-11-25T04:25:58.432946Z","shell.execute_reply.started":"2024-11-25T04:25:56.958160Z","shell.execute_reply":"2024-11-25T04:25:58.432046Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x79b3523886b0>"},"metadata":{}}],"execution_count":2},{"id":"2c2cbd17","cell_type":"code","source":"# Configure device: CUDA for GPU, otherwise CPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2c2cbd17","outputId":"12531188-6b4f-4917-b817-89c38e8b2977","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:25:58.434550Z","iopub.execute_input":"2024-11-25T04:25:58.435288Z","iopub.status.idle":"2024-11-25T04:25:58.478136Z","shell.execute_reply.started":"2024-11-25T04:25:58.435244Z","shell.execute_reply":"2024-11-25T04:25:58.477176Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":3},{"id":"19f79660-dc83-4703-9b63-5225045837d9","cell_type":"markdown","source":"Max Sequence length","metadata":{}},{"id":"9c6623a1","cell_type":"code","source":"#Constant for the model\nMAX_SEQ_LEN = 128 #Maximum Sequence length","metadata":{"id":"9c6623a1","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:25:58.713938Z","iopub.execute_input":"2024-11-25T04:25:58.714286Z","iopub.status.idle":"2024-11-25T04:25:58.718255Z","shell.execute_reply.started":"2024-11-25T04:25:58.714257Z","shell.execute_reply":"2024-11-25T04:25:58.717329Z"}},"outputs":[],"execution_count":4},{"id":"ef039801-6d54-45d3-a6eb-6240e1fcf43b","cell_type":"markdown","source":"### Positional Embedding\nPositional embedding module designed to add positional information to the input token embeddings, enabling the Transformer to understand the sequential order of tokens. Recomputes a positional embedding matrix based on sine and cosine functions. This matrix encodes positional information for each token in the sequence.\n\n\n**Inputs:**\n* d_model: Dimensionality of token embeddings.\n* max_seq_len: Maximum sequence length.\n\n**Output:**\n* Initializes the pos_embed_matrix attribute to store positional encodings.\n","metadata":{}},{"id":"3103d45f","cell_type":"code","source":"\nclass PositionalEmbedding(nn.Module):\n    \n    #Initializes the PositionalEmbedding module.\n    def __init__(self, d_model, max_seq_len = MAX_SEQ_LEN):\n        \"\"\"    \n        Args:\n        * d_model (int): The size of each token's embedding vector.\n        * max_seq_len (int): The maximum sequence length the model can handle.\n        \"\"\"\n        super().__init__()\n        self.pos_embed_matrix = torch.zeros(max_seq_len, d_model, device=device)\n        token_pos = torch.arange(0, max_seq_len, dtype = torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float()\n                             * (-math.log(10000.0)/d_model))\n        self.pos_embed_matrix[:, 0::2] = torch.sin(token_pos * div_term)\n        self.pos_embed_matrix[:, 1::2] = torch.cos(token_pos * div_term)\n        self.pos_embed_matrix = self.pos_embed_matrix.unsqueeze(0).transpose(0,1)\n\n    #Adds positional embeddings to the input tensor.\n    def forward(self, x):\n        \"\"\"\n        Args:\n        * x (torch.Tensor): Input tensor of shape [seq_len, batch_size, d_model].\n        Returns:\n        * torch.Tensor: The input tensor with positional embeddings added,\n        maintaining the same shape.\n        \"\"\"\n        # print(self.pos_embed_matrix.shape)\n        # print(x.shape)\n        return x + self.pos_embed_matrix[:x.size(0), :]\n\n","metadata":{"code_folding":[30,94],"id":"3103d45f","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:25:58.849895Z","iopub.execute_input":"2024-11-25T04:25:58.850229Z","iopub.status.idle":"2024-11-25T04:25:58.857365Z","shell.execute_reply.started":"2024-11-25T04:25:58.850201Z","shell.execute_reply":"2024-11-25T04:25:58.856444Z"}},"outputs":[],"execution_count":5},{"id":"e5c6b972-3c46-4db2-86ff-34fca1409253","cell_type":"markdown","source":"## MultiHeadAttention\nThe MultiHeadAttention module implements the multi-head attention mechanism, allowing the Transformer to focus on different parts of the sequence simultaneously. It performs scaled dot-product attention across multiple heads and combines the results to generate contextualized representations of the input.\n\n**Inputs:**\n\n* d_model: Dimensionality of token embeddings.\n* num_heads: Number of parallel attention heads.\n\n**Output:**\n\nInitializes the attention weights (W_q, W_k, W_v, W_o) and splits embeddings across heads.\n","metadata":{}},{"id":"087ebf10-d80c-4f9c-94e6-9b168c821f3b","cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n     # Initializes the MultiHeadAttention module.\n    def __init__(self, d_model = 512, num_heads = 8):\n        \"\"\"\n        Args:\n        * d_model (int): The embedding size of the input.\n        * num_heads (int): The number of attention heads.\n        \"\"\"\n        super().__init__()\n        assert d_model % num_heads == 0, 'Embedding size not compatible with num heads'\n\n        self.d_v = d_model // num_heads\n        self.d_k = self.d_v\n        self.num_heads = num_heads\n\n        # Define projection layers for queries, keys, and values\n        self.W_q = nn.Linear(d_model, d_model)\n        self.W_k = nn.Linear(d_model, d_model)\n        self.W_v = nn.Linear(d_model, d_model)\n        self.W_o = nn.Linear(d_model, d_model)\n\n    # Computes multi-head attention.\n    def forward(self, Q, K, V, mask = None):\n        \"\"\"\n        Args:\n        * Q (torch.Tensor): Query tensor of shape [batch_size, seq_len, d_model].\n        * K (torch.Tensor): Key tensor of shape [batch_size, seq_len, d_model].\n        * V (torch.Tensor): Value tensor of shape [batch_size, seq_len, d_model].\n        * mask (torch.Tensor, optional): Mask to prevent attention to certain positions.\n        \n        Returns:\n        * torch.Tensor: Attention outputs of shape [batch_size, seq_len, d_model].\n        * torch.Tensor: Attention weights.\n        \"\"\"\n        batch_size = Q.size(0)\n        \n        # Project Q, K, and V into the respective subspaces and reshape\n        Q = self.W_q(Q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2 )\n        K = self.W_k(K).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2 )\n        V = self.W_v(V).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2 )\n\n        # Compute scaled dot-product attention\n        weighted_values, attention = self.scale_dot_product(Q, K, V, mask)\n\n        # Concatenate attention heads and apply the output transformation\n        weighted_values = weighted_values.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads*self.d_k)\n        weighted_values = self.W_o(weighted_values)\n\n        return weighted_values, attention\n\n    #Computes scaled dot-product attention.\n    def scale_dot_product(self, Q, K, V, mask = None):\n        \"\"\"\n        Args:\n        * Q (torch.Tensor): Query tensor of shape [batch_size, num_heads, seq_len, d_k].\n        * K (torch.Tensor): Key tensor of shape [batch_size, num_heads, seq_len, d_k].\n        * V (torch.Tensor): Value tensor of shape [batch_size, num_heads, seq_len, d_k].\n        * mask (torch.Tensor, optional): Mask to prevent attention to certain positions.\n\n        Returns:\n        * torch.Tensor: Weighted sum of value vectors, shape [batch_size, num_heads, seq_len, d_k].\n        * torch.Tensor: Attention weights, shape [batch_size, num_heads, seq_len, seq_len].\n        \"\"\"\n        #Compute attention Scores\n        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n\n        #Apply mask if provided\n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, -1e9)\n\n        #Compute attention weights\n        attention = F.softmax(scores, dim = -1)\n\n        #Compute weighted sum\n        weighted_values = torch.matmul(attention, V)\n\n        return weighted_values, attention\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:26:00.433842Z","iopub.execute_input":"2024-11-25T04:26:00.434606Z","iopub.status.idle":"2024-11-25T04:26:00.444205Z","shell.execute_reply.started":"2024-11-25T04:26:00.434569Z","shell.execute_reply":"2024-11-25T04:26:00.443461Z"}},"outputs":[],"execution_count":6},{"id":"18aa5a28-28ce-431c-b03a-2c2ad8c2b078","cell_type":"markdown","source":"## PositionFeedForward\nThe PositionFeedForward module applies a two-layer feed-forward network to each position in the sequence independently. It introduces non-linearity with a ReLU activation and projects embeddings back to their original dimensions.\n\n**Inputs:**\n* d_model (int): Dimensionality of token embeddings.\n* d_ff (int): Size of the hidden feed-forward layer.\n\n**Outputs:**\n* Transformed tensor of shape [batch_size, seq_len, d_model].","metadata":{}},{"id":"e96153b1-3cd4-4123-a40b-71c837974ce2","cell_type":"code","source":"#Position-wise feed-forward network applied independently to each token in the sequence.\nclass PositionFeedForward(nn.Module):\n    \"\"\"\n    Attributes:\n        linear1 (nn.Linear): First linear transformation (expansion).\n        linear2 (nn.Linear): Second linear transformation (projection).\n    \"\"\"\n    # Initializes the feed-forward network.\n    def __init__(self, d_model, d_ff):\n        \"\"\"\n        Args:\n        * d_model (int): Size of the input embeddings.\n        * d_ff (int): Size of the hidden feed-forward layer.\n        \"\"\"\n        super().__init__()\n        self.linear1 = nn.Linear(d_model, d_ff)\n        self.linear2 = nn.Linear(d_ff, d_model)\n\n    #Applies the feed-forward transformation.    \n    def forward(self, x):\n        \"\"\"\n        Args:\n        * x (torch.Tensor): Input tensor of shape [batch_size, seq_len, d_model].\n        \n        Returns:\n        * torch.Tensor: Transformed tensor of the same shape.\n        \"\"\"\n        return self.linear2(F.relu(self.linear1(x)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:29:21.842932Z","iopub.execute_input":"2024-11-25T04:29:21.843273Z","iopub.status.idle":"2024-11-25T04:29:21.849194Z","shell.execute_reply.started":"2024-11-25T04:29:21.843241Z","shell.execute_reply":"2024-11-25T04:29:21.848259Z"}},"outputs":[],"execution_count":44},{"id":"b1b2087d-1ca1-4c1c-bd69-defef1844864","cell_type":"markdown","source":"## EncoderSubLayer\nFunctionality/Description:\nThe EncoderSubLayer combines self-attention, feed-forward networks, and residual connections with layer normalization. This forms the building block for the Transformer encoder.\n\n**Inputs:**\n\n* d_model (int): Dimensionality of token embeddings.\n* num_heads (int): Number of attention heads.\n* d_ff (int): Hidden layer size for the feed-forward network.\n* dropout (float): Dropout rate for regularization.\n  \n**Outputs:**\n* Transformed tensor of shape [batch_size, seq_len, d_model].","metadata":{}},{"id":"341029df-9725-417e-85f4-2ee067c46b69","cell_type":"code","source":"#Single sublayer of the Transformer encoder, combining self-attention,\n#feed-forward networks, and layer normalization.\nclass EncoderSubLayer(nn.Module):\n    \"\"\"\n    Attributes:\n        self_attn (MultiHeadAttention): Multi-head self-attention mechanism.\n        ffn (PositionFeedForward): Feed-forward network.\n        norm1, norm2 (nn.LayerNorm): Layer normalization layers.\n        dropout1, dropout2 (nn.Dropout): Dropout layers for regularization.\n    \"\"\"\n\n    # Initializes the encoder sublayer.\n    def __init__(self, d_model, num_heads, d_ff, dropout = 0.1):\n        \"\"\"\n        Args:\n        * d_model (int): Dimensionality of token embeddings.\n        * num_heads (int): Number of attention heads.\n        * d_ff (int): Hidden layer size for the feed-forward network.\n        * dropout (float): Dropout rate for regularization.\n        \"\"\"\n        super().__init__()\n        self.self_attn = MultiHeadAttention(d_model, num_heads)\n        self.ffn = PositionFeedForward(d_model, d_ff)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.droupout1 = nn.Dropout(dropout)\n        self.droupout2 = nn.Dropout(dropout)\n\n    # Applies self-attention and feed-forward transformation.\n    def forward(self, x, mask = None):\n        \"\"\"\n        Args:\n        * x (torch.Tensor): Input tensor of shape [batch_size, seq_len, d_model].\n        * mask (torch.Tensor, optional): Attention mask.\n        \n        Returns:\n        * torch.Tensor: Transformed tensor of the same shape.\n        \"\"\"\n        attention_score, _ = self.self_attn(x, x, x, mask)\n        x = x + self.droupout1(attention_score)\n        x = self.norm1(x)\n        x = x + self.droupout2(self.ffn(x))\n        return self.norm2(x)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:29:25.065276Z","iopub.execute_input":"2024-11-25T04:29:25.065661Z","iopub.status.idle":"2024-11-25T04:29:25.072196Z","shell.execute_reply.started":"2024-11-25T04:29:25.065623Z","shell.execute_reply":"2024-11-25T04:29:25.071379Z"}},"outputs":[],"execution_count":45},{"id":"5261ea0a-cd7c-4762-b81a-2b9bdf15af99","cell_type":"markdown","source":"## Encoder\nThe Encoder module consists of a stack of encoder sublayers, each applying self-attention and feed-forward transformations. This module processes input embeddings and outputs contextualized token representations.\n\n**Inputs:**\n* d_model (int): Dimensionality of token embeddings.\n* num_heads (int): Number of attention heads.\n* d_ff (int): Hidden layer size for the feed-forward network.\n* num_layers (int): Number of encoder sublayers in the stack.\n* dropout (float): Dropout rate for regularization.\n\n**Outputs:**\n* Contextualized token embeddings of shape [batch_size, seq_len, d_model].","metadata":{}},{"id":"f75de931-ec26-4cd7-90d8-980a45501a22","cell_type":"code","source":"#Transformer encoder consisting of multiple stacked encoder sublayers.\nclass Encoder(nn.Module):\n    \"\"\"\n    Attributes:\n        layers (nn.ModuleList): List of `EncoderSubLayer` instances.\n        norm (nn.LayerNorm): Layer normalization for the final output.\n    \"\"\"\n    # Initializes the encoder.\n    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n        \"\"\"\n        Args:\n        * d_model (int): Dimensionality of token embeddings.\n        * num_heads (int): Number of attention heads.\n        * d_ff (int): Hidden layer size for the feed-forward network.\n        * num_layers (int): Number of encoder sublayers.\n        * dropout (float): Dropout rate for regularization.\n        \"\"\"\n        super().__init__()\n        self.layers = nn.ModuleList([EncoderSubLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n        self.norm = nn.LayerNorm(d_model)\n\n    # Processes input embeddings through the encoder stack.\n    def forward(self, x, mask=None):\n        \"\"\"\n        Args:\n        * x (torch.Tensor): Input tensor of shape [batch_size, seq_len, d_model].\n        * mask (torch.Tensor, optional): Attention mask.\n        \n        Returns:\n        * torch.Tensor: Contextualized token embeddings of the same shape.\n        \"\"\"\n        for layer in self.layers:\n            x = layer(x, mask)\n        return self.norm(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:27:24.584090Z","iopub.execute_input":"2024-11-25T04:27:24.584737Z","iopub.status.idle":"2024-11-25T04:27:24.590638Z","shell.execute_reply.started":"2024-11-25T04:27:24.584702Z","shell.execute_reply":"2024-11-25T04:27:24.589675Z"}},"outputs":[],"execution_count":32},{"id":"ef2d7619-d26e-441a-81af-1a9aceda9062","cell_type":"markdown","source":"## DecoderSubLayer\nThe DecoderSubLayer processes target embeddings by combining self-attention, encoder-decoder cross-attention, and a feed-forward network. It uses residual connections and normalization to stabilize training.\n\n**Inputs:**\n\n* d_model (int): Dimensionality of token embeddings.\n* num_heads (int): Number of attention heads.\n* d_ff (int): Hidden layer size for the feed-forward network.\n* dropout (float): Dropout rate for regularization.\n\n**Outputs:**\n* Transformed tensor of shape [batch_size, seq_len, d_model].\n","metadata":{}},{"id":"8cb5bf0d-f0cf-4e32-a631-d13fdf7e8cb3","cell_type":"code","source":"#Single sublayer of the Transformer decoder, combining self-attention, \n# cross-attention, and feed-forward networks with normalization.\n\nclass DecoderSubLayer(nn.Module):\n    \"\"\"\n    Attributes:\n    * self_attn (MultiHeadAttention): Multi-head self-attention mechanism.\n    * cross_attn (MultiHeadAttention): Encoder-decoder cross-attention mechanism.\n    * feed_forward (PositionFeedForward): Feed-forward network.\n    * norm1, norm2, norm3 (nn.LayerNorm): Layer normalization layers.\n    * dropout1, dropout2, dropout3 (nn.Dropout): Dropout layers for regularization.\n    \"\"\"\n    \n    # Initializes the decoder sublayer.\n    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n        \"\"\"\n        Args:\n        * d_model (int): Dimensionality of token embeddings.\n        * num_heads (int): Number of attention heads.\n        * d_ff (int): Hidden layer size for the feed-forward network.\n        * dropout (float): Dropout rate for regularization.\n        \"\"\"\n        super().__init__()\n        self.self_attn = MultiHeadAttention(d_model, num_heads)\n        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n        self.feed_forward = PositionFeedForward(d_model, d_ff)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.norm3 = nn.LayerNorm(d_model)\n        self.dropout1 = nn.Dropout(dropout)\n        self.dropout2 = nn.Dropout(dropout)\n        self.dropout3 = nn.Dropout(dropout)\n\n    # Applies self-attention, cross-attention, and feed-forward transformation.\n    def forward(self, x, encoder_output, target_mask=None, encoder_mask=None):\n        \"\"\"\n        Args:\n        * x (torch.Tensor): Target embeddings of shape [batch_size, seq_len, d_model].\n        * encoder_output (torch.Tensor): Encoder output of shape [batch_size, seq_len, d_model].\n        * target_mask (torch.Tensor, optional): Mask for the target sequence.\n        * encoder_mask (torch.Tensor, optional): Mask for the encoder sequence.\n        \n        Returns:\n        * torch.Tensor: Transformed tensor of the same shape as input.\n        \"\"\"\n        # Self-attention with residual connection and normalization\n        attention_score, _ = self.self_attn(x, x, x, target_mask)\n        x = x + self.dropout1(attention_score)\n        x = self.norm1(x)\n\n        # Cross-attention with residual connection and normalization\n        encoder_attn, _ = self.cross_attn(x, encoder_output, encoder_output, encoder_mask)\n        x = x + self.dropout2(encoder_attn)\n        x = self.norm2(x)\n\n        # Feed-forward network with residual connection and normalization\n        ff_output = self.feed_forward(x)\n        x = x + self.dropout3(ff_output)\n        return self.norm3(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:27:27.288925Z","iopub.execute_input":"2024-11-25T04:27:27.289264Z","iopub.status.idle":"2024-11-25T04:27:27.297312Z","shell.execute_reply.started":"2024-11-25T04:27:27.289233Z","shell.execute_reply":"2024-11-25T04:27:27.296382Z"}},"outputs":[],"execution_count":33},{"id":"8c7fb7ec-1e0c-4f7b-af68-5fe072de5f44","cell_type":"markdown","source":"## Decoder\nThe Decoder module consists of a stack of decoder sublayers, each applying self-attention, cross-attention, and a feed-forward transformation. It generates predictions for the target sequence.\n\n**Inputs:**\n* d_model (int): Dimensionality of token embeddings.\n* num_heads (int): Number of attention heads.\n* d_ff (int): Hidden layer size for the feed-forward network.\n* num_layers (int): Number of decoder sublayers in the stack.\n* dropout (float): Dropout rate for regularization.\n\n**Outputs:**\n* Predictions for the target sequence of shape [batch_size, seq_len, d_model].","metadata":{}},{"id":"f27b5e24-94da-46d8-8169-b8761cca0e52","cell_type":"code","source":"#Transformer decoder consisting of multiple stacked decoder sublayers.\nclass Decoder(nn.Module):\n    \"\"\"\n    Attributes:\n    * layers (nn.ModuleList): List of `DecoderSubLayer` instances.\n    * norm (nn.LayerNorm): Layer normalization for the final output.\n    \"\"\"\n    \n    #Initializes the decoder.\n    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n        \"\"\"\n        Args:\n        * d_model (int): Dimensionality of token embeddings.\n        * num_heads (int): Number of attention heads.\n        * d_ff (int): Hidden layer size for the feed-forward network.\n        * num_layers (int): Number of decoder sublayers.\n        * dropout (float): Dropout rate for regularization.\n        \"\"\"\n        super().__init__()\n        self.layers = nn.ModuleList([DecoderSubLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n        self.norm = nn.LayerNorm(d_model)\n        \n    #Processes target embeddings through the decoder stack.\n    def forward(self, x, encoder_output, target_mask, encoder_mask):\n        \"\"\"\n        Args:\n        * x (torch.Tensor): Target embeddings of shape [batch_size, seq_len, d_model].\n        * encoder_output (torch.Tensor): Encoder output of shape [batch_size, seq_len, d_model].\n        * target_mask (torch.Tensor): Mask for the target sequence.\n        * encoder_mask (torch.Tensor): Mask for the encoder sequence.\n        \n        Returns:\n        * torch.Tensor: Predictions for the target sequence of the same shape as input.\n        \"\"\"\n        for layer in self.layers:\n            x = layer(x, encoder_output, target_mask, encoder_mask)\n        return self.norm(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:29:30.377912Z","iopub.execute_input":"2024-11-25T04:29:30.378252Z","iopub.status.idle":"2024-11-25T04:29:30.384683Z","shell.execute_reply.started":"2024-11-25T04:29:30.378220Z","shell.execute_reply":"2024-11-25T04:29:30.383684Z"}},"outputs":[],"execution_count":46},{"id":"7bb0a72e-2494-47c6-b689-1492efe0c4ef","cell_type":"markdown","source":"## Transformer\nCombines the Encoder and Decoder modules into the full Transformer architecture. Processes source and target sequences, generating logits for target vocabulary predictions.\n\n**Inputs:**\n* d_model (int): Dimensionality of token embeddings.\n* num_heads (int): Number of attention heads.\n* d_ff (int): Hidden layer size for the feed-forward network.\n* num_layers (int): Number of layers for both encoder and decoder.\n* input_vocab_size (int): Vocabulary size of the source language.\n* target_vocab_size (int): Vocabulary size of the target language.\n* max_len (int): Maximum sequence length.\n* dropout (float): Dropout rate for regularization.\n\n**Output:**\n* Logits for the target vocabulary of shape [batch_size, target_seq_len, target_vocab_size].","metadata":{}},{"id":"61070162","cell_type":"code","source":"class Transformer(nn.Module):\n\n    # Initializes the Transformer architecture.\n    def __init__(self, d_model, num_heads, d_ff, num_layers, input_vocab_size, target_vocab_size, max_len=MAX_SEQ_LEN, dropout=0.1):\n        \"\"\"\n        Args:\n        * d_model (int): Dimensionality of token embeddings.\n        * num_heads (int): Number of attention heads.\n        * d_ff (int): Hidden layer size for the feed-forward network.\n        * num_layers (int): Number of layers for both encoder and decoder.\n        * input_vocab_size (int): Vocabulary size of the source language.\n        * target_vocab_size (int): Vocabulary size of the target language.\n        * max_len (int): Maximum sequence length.\n        * dropout (float): Dropout rate for regularization.\n        \"\"\"\n        super().__init__()\n        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model)\n        self.decoder_embedding = nn.Embedding(target_vocab_size, d_model)\n        self.pos_embedding = PositionalEmbedding(d_model, max_len)\n        self.encoder = Encoder(d_model, num_heads, d_ff, num_layers, dropout)\n        self.decoder = Decoder(d_model, num_heads, d_ff, num_layers, dropout)\n        self.output_layer = nn.Linear(d_model, target_vocab_size)\n\n    def forward(self, source, target):\n        # Encoder mask\n        source_mask, target_mask = self.mask(source, target)\n        # Embedding and positional Encoding\n        source = self.encoder_embedding(source) * math.sqrt(self.encoder_embedding.embedding_dim)\n        source = self.pos_embedding(source)\n        # Encoder\n        encoder_output = self.encoder(source, source_mask)\n\n        # Decoder embedding and postional encoding\n        target = self.decoder_embedding(target) * math.sqrt(self.decoder_embedding.embedding_dim)\n        target = self.pos_embedding(target)\n        # Decoder\n        output = self.decoder(target, encoder_output, target_mask, source_mask)\n\n        return self.output_layer(output)\n\n\n\n    def mask(self, source, target):\n        source_mask = (source != 0).unsqueeze(1).unsqueeze(2)\n        target_mask = (target != 0).unsqueeze(1).unsqueeze(2)\n        size = target.size(1)\n        no_mask = torch.tril(torch.ones((1, size, size), device=device)).bool()\n        target_mask = target_mask & no_mask\n        return source_mask, target_mask","metadata":{"code_folding":[],"id":"61070162","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:29:33.372031Z","iopub.execute_input":"2024-11-25T04:29:33.372377Z","iopub.status.idle":"2024-11-25T04:29:33.380920Z","shell.execute_reply.started":"2024-11-25T04:29:33.372345Z","shell.execute_reply":"2024-11-25T04:29:33.379769Z"}},"outputs":[],"execution_count":47},{"id":"6da6b2d4","cell_type":"markdown","source":"#### Simple testing","metadata":{"heading_collapsed":true,"id":"6da6b2d4"}},{"id":"d40581d6","cell_type":"code","source":"seq_len_source = 10\nseq_len_target = 10\nbatch_size = 2\ninput_vocab_size = 50\ntarget_vocab_size = 50\n\nsource = torch.randint(1, input_vocab_size, (batch_size, seq_len_source))\ntarget = torch.randint(1, target_vocab_size, (batch_size, seq_len_target))","metadata":{"hidden":true,"id":"d40581d6","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:29:35.126079Z","iopub.execute_input":"2024-11-25T04:29:35.126517Z","iopub.status.idle":"2024-11-25T04:29:35.131787Z","shell.execute_reply.started":"2024-11-25T04:29:35.126477Z","shell.execute_reply":"2024-11-25T04:29:35.130894Z"}},"outputs":[],"execution_count":48},{"id":"fc7cf689","cell_type":"code","source":"d_model = 512\nnum_heads = 8\nd_ff = 2048\nnum_layers = 6\n\nmodel = Transformer(d_model, num_heads, d_ff, num_layers,\n                  input_vocab_size, target_vocab_size,\n                  max_len=MAX_SEQ_LEN, dropout=0.1)\n\nmodel = model.to(device)\nsource = source.to(device)\ntarget = target.to(device)","metadata":{"hidden":true,"id":"fc7cf689","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:29:36.580111Z","iopub.execute_input":"2024-11-25T04:29:36.580451Z","iopub.status.idle":"2024-11-25T04:29:37.048644Z","shell.execute_reply.started":"2024-11-25T04:29:36.580423Z","shell.execute_reply":"2024-11-25T04:29:37.047914Z"}},"outputs":[],"execution_count":49},{"id":"4618560e","cell_type":"code","source":"output = model(source, target)","metadata":{"hidden":true,"id":"4618560e","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:29:38.167982Z","iopub.execute_input":"2024-11-25T04:29:38.168328Z","iopub.status.idle":"2024-11-25T04:29:38.195754Z","shell.execute_reply.started":"2024-11-25T04:29:38.168297Z","shell.execute_reply":"2024-11-25T04:29:38.195153Z"}},"outputs":[],"execution_count":50},{"id":"ab0bc69d","cell_type":"code","source":"# Expected output shape -> [batch, seq_len_target, target_vocab_size] i.e. [2, 10, 50]\nprint(f'ouput.shape {output.shape}')","metadata":{"hidden":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"ab0bc69d","outputId":"22f0d85f-17ce-4276-e45a-48f9ac72d599","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:29:40.893335Z","iopub.execute_input":"2024-11-25T04:29:40.893693Z","iopub.status.idle":"2024-11-25T04:29:40.898824Z","shell.execute_reply.started":"2024-11-25T04:29:40.893666Z","shell.execute_reply":"2024-11-25T04:29:40.897832Z"}},"outputs":[{"name":"stdout","text":"ouput.shape torch.Size([2, 10, 50])\n","output_type":"stream"}],"execution_count":51},{"id":"0f4b2910","cell_type":"markdown","source":"## Translator English-Spanish\nThis code implements a sequence-to-sequence translator using the Transformer architecture. The translator takes English sentences as input and generates their corresponding translations in Spanish. The model uses the core components of a Transformer (encoder, decoder, multi-head attention, positional encoding, and feed-forward layers) to achieve this.\n\n**Functionality**\n\n* Dataset Preparation: The English-Spanish sentence pairs are preprocessed, cleaned, and tokenized.\nVocabulary indices are created for both languages.\nSentences are padded to a uniform length for batch processing.\n\n* Model Training:\n    * The model uses an encoder-decoder Transformer structure.\n    * The encoder processes English input sentences to generate contextualized embeddings.\n    * The decoder uses these embeddings and the Spanish target sentence (shifted for teacher forcing) to         generate the translated output.\n \n    \n\n* Translation Process:\n    * The model predicts the next token in the Spanish sequence for each step.\n    * Outputs are probabilities over the Spanish vocabulary, which are converted into tokens to form the\n      final translation.","metadata":{"id":"0f4b2910"}},{"id":"b02f8254-c3a4-4f7f-b6b7-05937f8cba37","cell_type":"markdown","source":"**FIle Readin**g\nThis section loads the English-Spanish sentence pairs from a .txt file, splits the data, and separates it into two lists: eng_sentences and spa_sentences.","metadata":{}},{"id":"869a7244","cell_type":"code","source":"PATH = dataset_path + '/eng-spa4.txt'\n\nwith open(PATH, 'r', encoding='utf-8') as f:\n    lines = f.readlines()\neng_spa_pairs = [line.strip().split('\\t') for line in lines if '\\t' in line]","metadata":{"id":"869a7244","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:29:47.191696Z","iopub.execute_input":"2024-11-25T04:29:47.192427Z","iopub.status.idle":"2024-11-25T04:29:47.195954Z","shell.execute_reply.started":"2024-11-25T04:29:47.192368Z","shell.execute_reply":"2024-11-25T04:29:47.195048Z"}},"outputs":[],"execution_count":53},{"id":"c930226f","cell_type":"code","source":"eng_spa_pairs[:10]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c930226f","outputId":"2928cf59-a741-403b-ac1b-7e317788c275","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:29:50.401774Z","iopub.execute_input":"2024-11-25T04:29:50.402385Z","iopub.status.idle":"2024-11-25T04:29:50.408247Z","shell.execute_reply.started":"2024-11-25T04:29:50.402343Z","shell.execute_reply":"2024-11-25T04:29:50.407407Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"[['Hi.', 'Hola.'],\n ['Ow!', '¡Ay!'],\n ['So?', '¿Y?'],\n ['So?', '¿Y qué?'],\n ['No.', 'No.'],\n ['Go.', 'Vaya.'],\n ['Ok!', '¡OK!'],\n ['So?', '¿Entonces?'],\n ['OK.', 'Bueno.'],\n ['Go!', '¡Sal!']]"},"metadata":{}}],"execution_count":55},{"id":"095f4037","cell_type":"code","source":"eng_sentences = [pair[0] for pair in eng_spa_pairs]\nspa_sentences = [pair[1] for pair in eng_spa_pairs]","metadata":{"id":"095f4037","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:29:52.792591Z","iopub.execute_input":"2024-11-25T04:29:52.793449Z","iopub.status.idle":"2024-11-25T04:29:52.842212Z","shell.execute_reply.started":"2024-11-25T04:29:52.793379Z","shell.execute_reply":"2024-11-25T04:29:52.841198Z"}},"outputs":[],"execution_count":56},{"id":"0d9e1c95","cell_type":"code","source":"print(eng_sentences[:10])\nprint(spa_sentences[:10])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0d9e1c95","outputId":"0130e8b3-5094-4191-d79f-b338e3aab0ba","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:29:54.181762Z","iopub.execute_input":"2024-11-25T04:29:54.182077Z","iopub.status.idle":"2024-11-25T04:29:54.186672Z","shell.execute_reply.started":"2024-11-25T04:29:54.182051Z","shell.execute_reply":"2024-11-25T04:29:54.185737Z"}},"outputs":[{"name":"stdout","text":"['Hi.', 'Ow!', 'So?', 'So?', 'No.', 'Go.', 'Ok!', 'So?', 'OK.', 'Go!']\n['Hola.', '¡Ay!', '¿Y?', '¿Y qué?', 'No.', 'Vaya.', '¡OK!', '¿Entonces?', 'Bueno.', '¡Sal!']\n","output_type":"stream"}],"execution_count":57},{"id":"30dcfd21-bf33-4681-84af-cdf39be1452d","cell_type":"markdown","source":"#### **Preprocessing Sentences**\n\nCleans sentences by removing special characters, converting to lowercase, and adding <sos> and <eos> tokens.","metadata":{}},{"id":"60d11478","cell_type":"code","source":"#Cleans and preprocesses a sentence.\ndef preprocess_sentence(sentence):\n    \"\"\"\n    Args:\n    * sentence (str): Input sentence to preprocess.\n\n    Returns:\n    * str: Preprocessed sentence with <sos> and <eos> tokens.\n    \"\"\"\n    sentence = sentence.lower().strip()\n    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n    sentence = re.sub(r\"[á]+\", \"a\", sentence)\n    sentence = re.sub(r\"[é]+\", \"e\", sentence)\n    sentence = re.sub(r\"[í]+\", \"i\", sentence)\n    sentence = re.sub(r\"[ó]+\", \"o\", sentence)\n    sentence = re.sub(r\"[ú]+\", \"u\", sentence)\n    sentence = re.sub(r\"[^a-z]+\", \" \", sentence)\n    sentence = sentence.strip()\n    sentence = '<sos> ' + sentence + ' <eos>'\n    return sentence","metadata":{"id":"60d11478","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:29:55.921573Z","iopub.execute_input":"2024-11-25T04:29:55.922156Z","iopub.status.idle":"2024-11-25T04:29:55.939561Z","shell.execute_reply.started":"2024-11-25T04:29:55.922121Z","shell.execute_reply":"2024-11-25T04:29:55.938681Z"}},"outputs":[],"execution_count":58},{"id":"b00a09f6-c881-4e39-a45b-c8e38d1feab5","cell_type":"markdown","source":"#### **Preprocessing Example**\n\nWe test our sentence preprocessing function on a test sentence","metadata":{}},{"id":"478f673b","cell_type":"code","source":"s1 = '¿Hola @ cómo estás? 123'","metadata":{"id":"478f673b","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:29:57.521676Z","iopub.execute_input":"2024-11-25T04:29:57.522010Z","iopub.status.idle":"2024-11-25T04:29:57.526124Z","shell.execute_reply.started":"2024-11-25T04:29:57.521981Z","shell.execute_reply":"2024-11-25T04:29:57.525206Z"}},"outputs":[],"execution_count":59},{"id":"96ac79c5","cell_type":"code","source":"print(s1)\nprint(preprocess_sentence(s1))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"96ac79c5","outputId":"a791f634-15cf-4fed-d784-c6681edd282a","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:29:59.091547Z","iopub.execute_input":"2024-11-25T04:29:59.092252Z","iopub.status.idle":"2024-11-25T04:29:59.096462Z","shell.execute_reply.started":"2024-11-25T04:29:59.092218Z","shell.execute_reply":"2024-11-25T04:29:59.095570Z"}},"outputs":[{"name":"stdout","text":"¿Hola @ cómo estás? 123\n<sos> hola como estas <eos>\n","output_type":"stream"}],"execution_count":60},{"id":"ac2de8a3-fcd8-4638-bfcd-a79cff944522","cell_type":"markdown","source":"We preprocess the sentences in both languages","metadata":{}},{"id":"d9fc9c4d","cell_type":"code","source":"eng_sentences = [preprocess_sentence(sentence) for sentence in eng_sentences]\nspa_sentences = [preprocess_sentence(sentence) for sentence in spa_sentences]","metadata":{"id":"d9fc9c4d","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:30:00.941917Z","iopub.execute_input":"2024-11-25T04:30:00.942538Z","iopub.status.idle":"2024-11-25T04:30:07.592840Z","shell.execute_reply.started":"2024-11-25T04:30:00.942504Z","shell.execute_reply":"2024-11-25T04:30:07.592082Z"}},"outputs":[],"execution_count":61},{"id":"f7a3b18d","cell_type":"code","source":"spa_sentences[:10]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f7a3b18d","outputId":"ac63870e-f33f-4e68-e577-f0713f1eb1b7","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:30:07.594197Z","iopub.execute_input":"2024-11-25T04:30:07.594505Z","iopub.status.idle":"2024-11-25T04:30:07.600141Z","shell.execute_reply.started":"2024-11-25T04:30:07.594478Z","shell.execute_reply":"2024-11-25T04:30:07.599341Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"['<sos> hola <eos>',\n '<sos> ay <eos>',\n '<sos> y <eos>',\n '<sos> y que <eos>',\n '<sos> no <eos>',\n '<sos> vaya <eos>',\n '<sos> ok <eos>',\n '<sos> entonces <eos>',\n '<sos> bueno <eos>',\n '<sos> sal <eos>']"},"metadata":{}}],"execution_count":62},{"id":"95fed410-8775-4700-bd14-4045b5a5b7a0","cell_type":"markdown","source":"#### **Building Vocabulary**\n\nCreates word-to-index and index-to-word mappings for tokenizing sentences.","metadata":{}},{"id":"97931cd3","cell_type":"code","source":"#Builds a vocabulary dictionary for the given sentences.\ndef build_vocab(sentences):\n    \"\"\"\n    Args:\n    * sentences (list): List of sentences.\n\n    Returns:\n    * word2idx (dict): Maps words to indices.\n    * idx2word (dict): Maps indices to words.\n    \"\"\"\n    words = [word for sentence in sentences for word in sentence.split()]\n    word_count = Counter(words)\n    sorted_word_counts = sorted(word_count.items(), key=lambda x:x[1], reverse=True)\n\n    # Create word-to-index and index-to-word mappings\n    word2idx = {word: idx for idx, (word, _) in enumerate(sorted_word_counts, 2)}\n    word2idx['<pad>'] = 0\n    word2idx['<unk>'] = 1\n    idx2word = {idx: word for word, idx in word2idx.items()}\n    return word2idx, idx2word","metadata":{"id":"97931cd3","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:30:07.601344Z","iopub.execute_input":"2024-11-25T04:30:07.602203Z","iopub.status.idle":"2024-11-25T04:30:07.611744Z","shell.execute_reply.started":"2024-11-25T04:30:07.602175Z","shell.execute_reply":"2024-11-25T04:30:07.610949Z"}},"outputs":[],"execution_count":63},{"id":"7fa8738e","cell_type":"code","source":"# Build vocabularies for English and Spanish\neng_word2idx, eng_idx2word = build_vocab(eng_sentences)\nspa_word2idx, spa_idx2word = build_vocab(spa_sentences)\n\neng_vocab_size = len(eng_word2idx)\nspa_vocab_size = len(spa_word2idx)","metadata":{"id":"7fa8738e","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:30:07.613047Z","iopub.execute_input":"2024-11-25T04:30:07.613321Z","iopub.status.idle":"2024-11-25T04:30:08.772148Z","shell.execute_reply.started":"2024-11-25T04:30:07.613297Z","shell.execute_reply":"2024-11-25T04:30:08.771447Z"}},"outputs":[],"execution_count":64},{"id":"79d6b633","cell_type":"code","source":"print(eng_vocab_size, spa_vocab_size)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"79d6b633","outputId":"d349465b-01e6-4bed-f896-14c6ddc4780d","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:30:12.521778Z","iopub.execute_input":"2024-11-25T04:30:12.522489Z","iopub.status.idle":"2024-11-25T04:30:12.527059Z","shell.execute_reply.started":"2024-11-25T04:30:12.522452Z","shell.execute_reply":"2024-11-25T04:30:12.526050Z"}},"outputs":[{"name":"stdout","text":"27688 46991\n","output_type":"stream"}],"execution_count":65},{"id":"6033331c-5f79-4511-829d-f47f8c41dd57","cell_type":"markdown","source":"#### **English Spanish Dataset**\nCustom PyTorch Dataset that handles the preprocessing and indexing of English and Spanish sentences. It transforms text-based sentences into numerical tensors that represent the tokens in the sentences.\n\n**Key Features:**\n\n* **Sentence Pair Storage:** The dataset stores English (eng_sentences) and Spanish (spa_sentences) sentences after preprocessing.\n* **Tokenization and Index Mapping:** Each sentence is tokenized (split into words). Words are replaced with their corresponding indices using word2idx mappings for each language.\n* **Tensor Conversion:** Each tokenized sentence is converted into a PyTorch tensor for efficient processing.\n* **Integration with DataLoader:** The __getitem__ method ensures compatibility with PyTorch's DataLoader, allowing the data to be accessed in batches.","metadata":{}},{"id":"e564017c","cell_type":"code","source":"#Initializes the dataset.\nclass EngSpaDataset(Dataset):\n    def __init__(self, eng_sentences, spa_sentences, eng_word2idx, spa_word2idx):\n        \"\"\"\n        Args:\n        * eng_sentences (list): List of English sentences.\n        * spa_sentences (list): List of Spanish sentences.\n        * eng_word2idx (dict): Vocabulary mapping for English (word to index).\n        * spa_word2idx (dict): Vocabulary mapping for Spanish (word to index).\n        \"\"\"\n        self.eng_sentences = eng_sentences\n        self.spa_sentences = spa_sentences\n        self.eng_word2idx = eng_word2idx\n        self.spa_word2idx = spa_word2idx\n\n    def __len__(self):\n        \"\"\"\n        Returns:\n        * int: Number of sentence pairs in the dataset.\n        \"\"\"\n        return len(self.eng_sentences)\n\n    # Retrieves a specific pair of sentences by index.\n    def __getitem__(self, idx\n        \"\"\"\n        Args:\n        * idx (int): Index of the sentence pair.\n\n        Returns:\n        * torch.Tensor: Tokenized and indexed English sentence.\n        * torch.Tensor: Tokenized and indexed Spanish sentence.\n        \"\"\"\n        eng_sentence = self.eng_sentences[idx]\n        spa_sentence = self.spa_sentences[idx]\n        # return tokens idxs\n        eng_idxs = [self.eng_word2idx.get(word, self.eng_word2idx['<unk>']) for word in eng_sentence.split()]\n        spa_idxs = [self.spa_word2idx.get(word, self.spa_word2idx['<unk>']) for word in spa_sentence.split()]\n\n        return torch.tensor(eng_idxs), torch.tensor(spa_idxs)","metadata":{"id":"e564017c","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:30:14.371747Z","iopub.execute_input":"2024-11-25T04:30:14.372097Z","iopub.status.idle":"2024-11-25T04:30:14.378513Z","shell.execute_reply.started":"2024-11-25T04:30:14.372066Z","shell.execute_reply":"2024-11-25T04:30:14.377578Z"}},"outputs":[],"execution_count":66},{"id":"17d62e1e-420c-4385-ad41-efd3676e4fc6","cell_type":"markdown","source":"#### Collate Function\nThe DataLoader is used to handle batching and padding of the dataset. Since sentences in the dataset have varying lengths, they need to be padded to a uniform length to form batches.","metadata":{}},{"id":"b579577b","cell_type":"code","source":"#Custom collate function to pad sentences in a batch.\ndef collate_fn(batch):\n    \"\"\"\n    Args:\n    * batch (list of tuples): Each tuple contains an English tensor and a Spanish tensor.\n\n    Returns:\n    * torch.Tensor: Padded batch of English sentences.\n    * torch.Tensor: Padded batch of Spanish sentences.\n    \"\"\"\n    eng_batch, spa_batch = zip(*batch)\n\n    # Pad sentences to uniform length\n    eng_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in eng_batch]\n    spa_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in spa_batch]\n    eng_batch = torch.nn.utils.rnn.pad_sequence(eng_batch, batch_first=True, padding_value=0)\n    spa_batch = torch.nn.utils.rnn.pad_sequence(spa_batch, batch_first=True, padding_value=0)\n    return eng_batch, spa_batch","metadata":{"id":"b579577b","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:30:16.252150Z","iopub.execute_input":"2024-11-25T04:30:16.253072Z","iopub.status.idle":"2024-11-25T04:30:16.258352Z","shell.execute_reply.started":"2024-11-25T04:30:16.253033Z","shell.execute_reply":"2024-11-25T04:30:16.257328Z"}},"outputs":[],"execution_count":67},{"id":"f6d56705-b9c8-4a35-b544-bb35fae54f69","cell_type":"markdown","source":"#### Train Function\nIt handles the process of iterating through the data, feeding it into the model, calculating the loss, and updating the model's parameters to minimize the loss.\n\n**Functionality:**\n* Loops through the dataset in batches for a specified number of epochs.\n* Prepares the input data and targets for the model.\n* Uses teacher forcing by feeding the previous target token during training.\n* Computes the loss for each prediction and updates the model parameters using backpropagation.\n* Logs the training progress and loss for each epoch.\n\n**Inputs:**\n* model: The Transformer model to be trained.\n* dataloader: DataLoader that provides batches of input and target tensors.\n* loss_function: The function used to compute the loss (e.g., CrossEntropyLoss).\n* optimiser: The optimizer used for gradient descent (e.g., Adam).\n* epochs: Number of iterations over the entire dataset.\n\n**Outputs:**\n* Trained model with updated parameters.\n* Loss values logged for each epoch.\n","metadata":{}},{"id":"8d514b7c","cell_type":"code","source":"#Trains the Transformer model on the given dataset.\ndef train(model, dataloader, loss_function, optimiser, epochs):\n    \"\"\"\n    Args:\n    * model: Transformer model to be trained.\n    * dataloader: PyTorch DataLoader providing batches of tokenized sentences.\n    * loss_function: Loss function (e.g., CrossEntropyLoss) for token prediction.\n    * optimiser: Optimizer (e.g., Adam) for updating model parameters.\n    * epochs: Number of epochs for training.\n\n    Returns:\n    None\n    \"\"\"\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n\n        # Create a progress bar for the epoch using tqdm.\n        loop = tqdm(dataloader, desc=f'Epoch {epoch + 1}/{epochs}')\n\n        # Iterate through batches in the DataLoader.\n        for eng_batch, spa_batch in loop:\n            eng_batch = eng_batch.to(device)\n            spa_batch = spa_batch.to(device)\n            # Decoder preprocessing\n            target_input = spa_batch[:, :-1]\n            target_output = spa_batch[:, 1:].contiguous().view(-1)\n            # Zero grads\n            optimiser.zero_grad()\n            # run model\n            output = model(eng_batch, target_input)\n            output = output.view(-1, output.size(-1))\n            # loss\\\n            loss = loss_function(output, target_output)\n            # gradient and update parameters\n            loss.backward()\n            optimiser.step()\n\n            # Accumulate the batch loss into total loss.\n            total_loss += loss.item()\n\n            # Update the progress bar with the current loss value.\n            loop.set_postfix(loss=loss.item())\n\n        avg_loss = total_loss/len(dataloader)\n        print(f'Epoch: {epoch}/{epochs}, Loss: {avg_loss:.4f}')\n","metadata":{"id":"8d514b7c","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:30:20.431949Z","iopub.execute_input":"2024-11-25T04:30:20.432294Z","iopub.status.idle":"2024-11-25T04:30:20.438809Z","shell.execute_reply.started":"2024-11-25T04:30:20.432264Z","shell.execute_reply":"2024-11-25T04:30:20.437989Z"}},"outputs":[],"execution_count":68},{"id":"cf2c2b6e-e1a7-489b-bb5d-397bfc758a69","cell_type":"markdown","source":"#### Batch Size and DataLoader Creation\n* BATCH_SIZE defines the number of samples to process at once.\n* EngSpaDataset processes the English and Spanish sentence pairs into tensors of token indices.\n* DataLoader organizes the dataset into batches and shuffles the data at the start of each epoch for randomness.","metadata":{}},{"id":"2379ea72","cell_type":"code","source":"BATCH_SIZE = 64 #define batch size\ndataset = EngSpaDataset(eng_sentences, spa_sentences, eng_word2idx, spa_word2idx) #create dataset\ndataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn) # Initialize DataLoader.","metadata":{"id":"2379ea72","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:30:23.671498Z","iopub.execute_input":"2024-11-25T04:30:23.671848Z","iopub.status.idle":"2024-11-25T04:30:23.676519Z","shell.execute_reply.started":"2024-11-25T04:30:23.671818Z","shell.execute_reply":"2024-11-25T04:30:23.675647Z"}},"outputs":[],"execution_count":69},{"id":"56c85d96-0a7b-4a16-ba74-78a598c65427","cell_type":"markdown","source":"#### **Model Initialization**\nInitializes a Transformer model with the specified architecture:\n * d_model=512: Each token is represented as a 512-dimensional embedding.\n * num_heads=8: Multi-head attention divides d_model into 8 parts for parallel processing. \n * num_layers=6: The encoder and decoder each have 6 layers.\n * Vocabulary sizes and maximum sequence length are set based on the dataset.\n","metadata":{}},{"id":"e08eef6a","cell_type":"code","source":"model = Transformer(\n    d_model=512,  # Embedding dimension.\n    num_heads=8,  # Number of attention heads.\n    d_ff=2048,  # Size of feed-forward hidden layers.\n    num_layers=6,  # Number of encoder/decoder layers.\n    input_vocab_size=eng_vocab_size,  # Size of the English vocabulary.\n    target_vocab_size=spa_vocab_size,  # Size of the Spanish vocabulary.\n    max_len=MAX_SEQ_LEN,  # Maximum sequence length.\n    dropout=0.1  # Dropout rate.\n)","metadata":{"id":"e08eef6a","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:30:25.551684Z","iopub.execute_input":"2024-11-25T04:30:25.552033Z","iopub.status.idle":"2024-11-25T04:30:26.489560Z","shell.execute_reply.started":"2024-11-25T04:30:25.552001Z","shell.execute_reply":"2024-11-25T04:30:26.488765Z"}},"outputs":[],"execution_count":70},{"id":"1156c7f1-7264-47c3-b74b-9a8e9464fa95","cell_type":"markdown","source":"#### Loss Function and Optimizer\n* nn.CrossEntropyLoss: Computes the loss for predicting each token, ignoring <pad> tokens (ignore_index=0).\n* optim.Adam: Optimizes model parameters with a learning rate of 0.0001.\n","metadata":{}},{"id":"a1181a12","cell_type":"code","source":"model = model.to(device)\nprint(device)\n\nloss_function = nn.CrossEntropyLoss(ignore_index=0)\noptimiser = optim.Adam(model.parameters(), lr=0.0001)","metadata":{"id":"a1181a12","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:30:27.381061Z","iopub.execute_input":"2024-11-25T04:30:27.381443Z","iopub.status.idle":"2024-11-25T04:30:28.189954Z","shell.execute_reply.started":"2024-11-25T04:30:27.381373Z","shell.execute_reply":"2024-11-25T04:30:28.189122Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":71},{"id":"d4d93aee-ae25-4410-83ad-f5c9c2063318","cell_type":"markdown","source":"##### We train the translation model","metadata":{}},{"id":"14e265e9","cell_type":"code","source":"train(model, dataloader, loss_function, optimiser, epochs = 5)","metadata":{"id":"14e265e9","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T04:30:43.922170Z","iopub.execute_input":"2024-11-25T04:30:43.922582Z","iopub.status.idle":"2024-11-25T05:23:37.176948Z","shell.execute_reply.started":"2024-11-25T04:30:43.922541Z","shell.execute_reply":"2024-11-25T05:23:37.175863Z"}},"outputs":[{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 4173/4173 [10:35<00:00,  6.57it/s, loss=2.25]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 0/5, Loss: 3.5424\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 4173/4173 [10:34<00:00,  6.57it/s, loss=1.28]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1/5, Loss: 2.1964\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 4173/4173 [10:33<00:00,  6.59it/s, loss=1.22] \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 2/5, Loss: 1.6991\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 4173/4173 [10:34<00:00,  6.58it/s, loss=1.2]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch: 3/5, Loss: 1.3707\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 4173/4173 [10:35<00:00,  6.56it/s, loss=1.13] ","output_type":"stream"},{"name":"stdout","text":"Epoch: 4/5, Loss: 1.1207\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":73},{"id":"cd625fba-6139-43da-9dcb-e2107fd67ae6","cell_type":"markdown","source":"#### Analysis and Conclusions\n**Training Results**\nThe training loss values decrease consistently across the epochs, as shown in the logs:\n\n* Epoch 1: Loss = 3.5424\n* Epoch 2: Loss = 2.1964\n* Epoch 3: Loss = 1.6991\n* Epoch 4: Loss = 1.3707\n* Epoch 5: Loss = 1.1207\n\nThis steady decrease in loss demonstrates that the Transformer model successfully learns patterns in the dataset. The final loss of 1.1207 suggests that the model has effectively minimized its prediction error, showing good convergence.","metadata":{}},{"id":"333e343a-7f15-4890-8e90-5a1c9456048a","cell_type":"markdown","source":"We save the model","metadata":{}},{"id":"1d271146","cell_type":"code","source":"torch.save(model.state_dict(), \"translator_model.pth\")\nprint(\"Model saved to translator_model.pth\")","metadata":{"id":"1d271146","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T05:24:11.799956Z","iopub.execute_input":"2024-11-25T05:24:11.800906Z","iopub.status.idle":"2024-11-25T05:24:12.556221Z","shell.execute_reply.started":"2024-11-25T05:24:11.800870Z","shell.execute_reply":"2024-11-25T05:24:12.555308Z"}},"outputs":[{"name":"stdout","text":"Model saved to translator_model.pth\n","output_type":"stream"}],"execution_count":74},{"id":"187d5f62-9d36-4cfc-b067-bf17c0749ff8","cell_type":"markdown","source":"## Model Evaluation\n### Functions for evaluation","metadata":{}},{"id":"50740746","cell_type":"code","source":"#Converts a sentence into token indices.\ndef sentence_to_indices(sentence, word2idx):\n    \"\"\"\n    Args:\n    * sentence (str): The input sentence to be tokenized.\n    * word2idx (dict): Vocabulary mapping words to indices.\n\n    Returns:\n    * list[int]: Token indices representing the sentence.\n    \"\"\"\n    return [word2idx.get(word, word2idx['<unk>']) for word in sentence.split()]\n\n#Converts a list of token indices into a sentence.\ndef indices_to_sentence(indices, idx2word):\n    \"\"\"\n    Args:\n    * indices (list[int]): List of token indices.\n    * idx2word (dict): Vocabulary mapping indices to words.\n\n    Returns:\n    * str: Human-readable sentence reconstructed from indices.\n    \"\"\"\n    return ' '.join([idx2word[idx] for idx in indices if idx in idx2word and idx2word[idx] != '<pad>'])\n\n\n#Translates an English sentence into Spanish using the Transformer model.\ndef translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n    \"\"\"\n    Args:\n    * model (Transformer): The trained Transformer model.\n    * sentence (str): The input English sentence.\n    * eng_word2idx (dict): English vocabulary mapping words to indices.\n    * spa_idx2word (dict): Spanish vocabulary mapping indices to words.\n    * max_len (int): Maximum length of the target sentence.\n    * device (str): Device to use for translation ('cpu' or 'cuda').\n\n    Returns:\n    * str: Translated Spanish sentence.\n    \"\"\"\n    model.eval()\n    sentence = preprocess_sentence(sentence)\n\n    # Convert the input sentence to indices\n    input_indices = sentence_to_indices(sentence, eng_word2idx)\n    input_tensor = torch.tensor(input_indices).unsqueeze(0).to(device)\n\n    # Initialize the target tensor with <sos> token\n    tgt_indices = [spa_word2idx['<sos>']]\n    tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        for _ in range(max_len):\n            # Forward pass through the model\n            output = model(input_tensor, tgt_tensor)\n            output = output.squeeze(0)  \n            \n            # Get the most probable next token\n            next_token = output.argmax(dim=-1)[-1].item()\n            tgt_indices.append(next_token)\n            tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n\n            # Stop if the <eos> token is generated\n            if next_token == spa_word2idx['<eos>']:\n                break\n\n    return indices_to_sentence(tgt_indices, spa_idx2word)","metadata":{"code_folding":[],"id":"50740746","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T05:24:20.998690Z","iopub.execute_input":"2024-11-25T05:24:20.999550Z","iopub.status.idle":"2024-11-25T05:24:21.007378Z","shell.execute_reply.started":"2024-11-25T05:24:20.999514Z","shell.execute_reply":"2024-11-25T05:24:21.006451Z"}},"outputs":[],"execution_count":77},{"id":"55ff499d-bc3e-4f36-a20b-98f08f0c6d99","cell_type":"markdown","source":"#### Evaluating Translations \nEvaluates the translation performance of the model on a list of test sentences. For each sentence, it prints the input sentence and its translation.","metadata":{}},{"id":"c2c0db72","cell_type":"code","source":"#Evaluates the model's translations for a list of test sentences.\ndef evaluate_translations(model, sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n    \"\"\"\n    Args:\n    * model (Transformer): The trained Transformer model.\n    * sentences (list[str]): List of English sentences to translate.\n    * eng_word2idx (dict): English vocabulary mapping words to indices.\n    * spa_idx2word (dict): Spanish vocabulary mapping indices to words.\n    * max_len (int): Maximum length of the target sentence.\n    * device (str): Device to use for translation ('cpu' or 'cuda').\n\n    Returns:\n    None\n    \"\"\"\n    for sentence in sentences:\n        translation = translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len, device)\n        print(f'Input sentence: {sentence}')\n        print(f'Traducción: {translation}')\n        print()\n\n\n","metadata":{"code_folding":[15],"id":"c2c0db72","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T05:24:24.087154Z","iopub.execute_input":"2024-11-25T05:24:24.087850Z","iopub.status.idle":"2024-11-25T05:24:24.092951Z","shell.execute_reply.started":"2024-11-25T05:24:24.087815Z","shell.execute_reply":"2024-11-25T05:24:24.091800Z"}},"outputs":[],"execution_count":78},{"id":"4b78e672-84b6-4dec-b8d2-bf589a3241a8","cell_type":"markdown","source":"### Test sentences chosen by the team","metadata":{}},{"id":"acc74423-f29c-4738-a61f-6278cf19ca73","cell_type":"code","source":"# Example sentences to test the translator chosen by the team\ntest_sentences = [\n    \"Hello, how are you?\",\n    \"I am learning artificial intelligence.\",\n    \"Artificial intelligence is great.\",\n    \"Good night!\",\n    \"Have a Great day!\",\n    \"Let´s go get some ice cream\",\n    \"Today is my Birthday!\",\n    \"I am really excited to be here with you\",\n    \"We need your help with the project\",\n    \"You know it is due tomorrow\",\n    \"Do you want to go to the park later?\",\n    \"This is the first time I am traveling abroad.\",\n    \"They are watching a movie together.\",\n    \"I enjoy playing soccer with my friends.\",\n    \"My brother is studying at the university.\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T05:24:26.477365Z","iopub.execute_input":"2024-11-25T05:24:26.478110Z","iopub.status.idle":"2024-11-25T05:24:26.482531Z","shell.execute_reply.started":"2024-11-25T05:24:26.478074Z","shell.execute_reply":"2024-11-25T05:24:26.481476Z"}},"outputs":[],"execution_count":79},{"id":"d030dde1-aefd-45af-8258-99fbbd5d1a78","cell_type":"markdown","source":"**We evaluate the model on the sentences**","metadata":{}},{"id":"4ceefe95","cell_type":"code","source":"# Set the device to 'cpu' or 'cuda' as needed\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Evaluate translations\nevaluate_translations(model, test_sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device=device)","metadata":{"id":"4ceefe95","trusted":true,"execution":{"iopub.status.busy":"2024-11-25T05:43:51.975291Z","iopub.execute_input":"2024-11-25T05:43:51.976155Z","iopub.status.idle":"2024-11-25T05:43:52.970001Z","shell.execute_reply.started":"2024-11-25T05:43:51.976117Z","shell.execute_reply":"2024-11-25T05:43:52.969035Z"}},"outputs":[{"name":"stdout","text":"Input sentence: Hello, how are you?\nTraducción: <sos> hola como estas <eos>\n\nInput sentence: I am learning artificial intelligence.\nTraducción: <sos> estoy aprendiendo inteligencia artificial <eos>\n\nInput sentence: Artificial intelligence is great.\nTraducción: <sos> la inteligencia artificial es genial <eos>\n\nInput sentence: Good night!\nTraducción: <sos> buenas noches <eos>\n\nInput sentence: Have a Great day!\nTraducción: <sos> que tengas un gran dia <eos>\n\nInput sentence: Let´s go get some ice cream\nTraducción: <sos> vamos a ir a un helado <eos>\n\nInput sentence: Today is my Birthday!\nTraducción: <sos> hoy es mi cumplea os <eos>\n\nInput sentence: I am really excited to be here with you\nTraducción: <sos> estoy muy emocionada por estar aqui contigo <eos>\n\nInput sentence: We need your help with the project\nTraducción: <sos> necesitamos tu ayuda con la ayuda <eos>\n\nInput sentence: You know it is due tomorrow\nTraducción: <sos> sabes que va ma ana <eos>\n\nInput sentence: Do you want to go to the park later?\nTraducción: <sos> queres ir al parque mas tarde <eos>\n\nInput sentence: This is the first time I am traveling abroad.\nTraducción: <sos> es la primera vez que viaje en el extranjero <eos>\n\nInput sentence: They are watching a movie together.\nTraducción: <sos> estan viendo una pelicula juntos <eos>\n\nInput sentence: I enjoy playing soccer with my friends.\nTraducción: <sos> me gusta jugar futbol con mis amigos <eos>\n\nInput sentence: My brother is studying at the university.\nTraducción: <sos> mi hermano esta estudiando en la universidad <eos>\n\n","output_type":"stream"}],"execution_count":82},{"id":"1eca5a81-30d3-4676-9b42-d974e418780d","cell_type":"markdown","source":"### Results analysis\n\n**Evaluation of Translations**\n\nThe translations generated for the test sentences show promising results. Here's an analysis of the output:\n\n* **Accurate Translations:**\n    * Many of the test sentences are translated correctly, maintaining the meaning and structure of the original English sentence. Examples include:\n        * \"Hello, how are you?\" → \"hola como estas\"\n        * \"Good night!\" → \"buenas noches\"\n        * \"Artificial intelligence is great.\" → \"la inteligencia artificial es genial\"\n          \n* **Maintaining Context:**\n    * The translations preserve the semantic meaning of the original sentences. For instance:\n        * \"Let's go get some ice cream.\" → \"vamos a ir a un helado\"\n    * While slightly unnatural, it still captures the intended meaning.\n\n\n\n* **Potential Improvements:**\n     * Some translations could be refined for grammatical accuracy or fluency in Spanish. For instance:\n         * \"We need your help with the project.\" → \"necesitamos tu ayuda con la ayuda\"\n    * Here, the repetition of \"ayuda\" could be improved.\n\n* **Handling of Special Tokens:**\n    * The <sos> and <eos> tokens are correctly included in the output, indicating that the model has learned to manage sequence boundaries effectively.","metadata":{}}]}